{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование текста в эмбединги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Использование моделей из sentence_transformers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.2011\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем модель для создания embedding-векторов\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def cosine_similarity(text1, text2):\n",
    "    # Преобразуем текст в embedding-векторы\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    \n",
    "    # Вычисляем косинусное сходство\n",
    "    cosine_sim = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    \n",
    "    return cosine_sim.item()  # Возвращаем значение сходства как float\n",
    "\n",
    "# Пример данных\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение продает бургеры\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6362\n"
     ]
    }
   ],
   "source": [
    "# Пример данных\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение использует MacOS и Windows\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Использование моделей Bert*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7674\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Загружаем токенайзер и модель RuBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    # Токенизация текста и преобразование в тензоры\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    # Получаем выход модели\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Используем эмбеддинг CLS-токена (первого токена) как представление текста\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "    return embedding\n",
    "\n",
    "def cosine_similarity_rubert(text1, text2):\n",
    "    # Получаем эмбеддинги для текста 1 и текста 2\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Вычисляем косинусное сходство\n",
    "    cosine_sim = 1 - cosine(embedding1, embedding2)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "# Пример данных\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение поддерживает Windows и macOS.\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity_rubert(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Пример данных\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение продает бургеры\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity_rubert(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Использование тревиальных векторизаторов(не работает)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x72cf35894fb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.downloader.load('word2vec-ruscorpora-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Загружаем предобученную модель Word2Vec\n",
    "model = api.load('word2vec-ruscorpora-300')\n",
    "\n",
    "def get_embedding(sentence):\n",
    "    # Токенизируем предложение и получаем эмбеддинги для каждого слова\n",
    "    words = sentence.split()\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Проверяем, есть ли слово в модели\n",
    "        if word in model:\n",
    "            embeddings.append(model[word])\n",
    "    \n",
    "    # Если не найдено ни одно слово, возвращаем нулевой вектор\n",
    "    if not embeddings:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    # Усредняем эмбеддинги слов\n",
    "    sentence_embedding = np.mean(embeddings, axis=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "def cosine_similarity(text1, text2):\n",
    "    # Получаем эмбеддинги для текстов\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Вычисляем косинусное сходство\n",
    "    cosine_sim = 1 - cosine(embedding1, embedding2)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "# Пример использования\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение поддерживает Windows и macOS.\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*FastText - у меня оперативы не хватило*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "\n",
    "# fasttext.util.download_model('ru', if_exists='ignore')\n",
    "# Загрузка предобученной модели\n",
    "model = fasttext.load_model('cc.ru.300.bin')\n",
    "\n",
    "# Получение среднего эмбеддинга для предложения\n",
    "def get_sentence_embedding(text):\n",
    "    words = text.split()\n",
    "    word_embeddings = [model.get_word_vector(word) for word in words]\n",
    "    return np.mean(word_embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/__init__.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\\n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \\n\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/home/user/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GloVe\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[0;32m~/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torch/_ops.py:1350\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1345\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1350\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/usr/lib/python3.12/ctypes/__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /home/user/Coding/easydocs/model-prototype/model-analyse/venv/lib/python3.12/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import GloVe\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем предобученные GloVe эмбеддинги\n",
    "glove = GloVe(name='6B', dim=100)  # Вы можете выбрать размер 50, 100, 200, 300\n",
    "\n",
    "def get_embedding(sentence):\n",
    "    # Токенизируем предложение и получаем эмбеддинги для каждого слова\n",
    "    words = sentence.split()\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Проверяем, есть ли слово в GloVe\n",
    "        if word in glove.stoi:\n",
    "            embeddings.append(glove[word])\n",
    "    \n",
    "    # Если не найдено ни одно слово, возвращаем нулевой вектор\n",
    "    if not embeddings:\n",
    "        return torch.zeros(glove.dim)\n",
    "    \n",
    "    # Усредняем эмбеддинги слов\n",
    "    sentence_embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "def cosine_similarity(text1, text2):\n",
    "    # Получаем эмбеддинги для текстов\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Вычисляем косинусное сходство\n",
    "    cosine_sim = 1 - cosine(embedding1.numpy(), embedding2.numpy())\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "# Пример использования\n",
    "question = \"Какую операционную систему поддерживает приложение?\"\n",
    "context = \"Наше приложение поддерживает Windows и macOS.\"\n",
    "\n",
    "# Вычисляем косинусное сходство\n",
    "similarity_score = cosine_similarity(question, context)\n",
    "print(f\"Cosine Similarity: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
